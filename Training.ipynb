{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_Text</th>\n",
       "      <th>Punctuation_Counts_before</th>\n",
       "      <th>Diacritic_Counts</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>وكان الرئيس الاوكراني المؤقت  الكسندر تورتشينو...</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>وكان الرئيس الاوكراني المؤقت الكسندر تورتشينوف...</td>\n",
       "      <td>وكان رئس وكر ؤقت كسندر تورتشينوف امر سحب قوت ا...</td>\n",
       "      <td>كان رئيس الاوكراني المؤقت الكسندر تورتشينوف مر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بحلول عام 2050 ستحتاج مصر الي 21 مليار متر مكع...</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>بحلول عام 2050 ستحتاج مصر الي 21 مليار متر مكع...</td>\n",
       "      <td>حلل عام 2050 حاج مصر الي 21 لير متر كعب حصت حل...</td>\n",
       "      <td>حلول عام 2050 احتاج مصر ال 21 مليار متر مكعب ح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وذكرت وكاله الانباء المحليه  جي ان اس  ان جماع...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>وذكرت وكاله الانباء المحليه جي ان اس ان جماعه ...</td>\n",
       "      <td>ذكر وكل باء حله جي ان اس ان جمع جيش حمد تشدد ا...</td>\n",
       "      <td>ذكر كال الانباء المحليه جي ان اس ان جماع جيش م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ووقع اختياره علي واد عمقه 800 متر محاط بثماني ...</td>\n",
       "      <td>378</td>\n",
       "      <td>15</td>\n",
       "      <td>ووقع اختياره علي واد عمقه 800 متر محاط بثماني ...</td>\n",
       "      <td>وقع خير علي واد عمق 800 متر حاط بثم قمم حده تش...</td>\n",
       "      <td>وقع اختيار علي وادي عمق 800 متر محاط بثماني قم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مسلح حوثي في اب  وقال المصدر ان المسلحين الحوث...</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>مسلح حوثي اب وقال المصدر ان المسلحين الحوثيين ...</td>\n",
       "      <td>سلح حوث اب وقل صدر ان سلح حوث هجم شطء حرك همي ...</td>\n",
       "      <td>مسلح حوثي اب قال مصدر ان مسلح الحوثيين هاجم نش...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_Text  \\\n",
       "0  وكان الرئيس الاوكراني المؤقت  الكسندر تورتشينو...   \n",
       "1  بحلول عام 2050 ستحتاج مصر الي 21 مليار متر مكع...   \n",
       "2  وذكرت وكاله الانباء المحليه  جي ان اس  ان جماع...   \n",
       "3  ووقع اختياره علي واد عمقه 800 متر محاط بثماني ...   \n",
       "4  مسلح حوثي في اب  وقال المصدر ان المسلحين الحوث...   \n",
       "\n",
       "   Punctuation_Counts_before  Diacritic_Counts  \\\n",
       "0                        146                 0   \n",
       "1                         74                 1   \n",
       "2                         38                 0   \n",
       "3                        378                15   \n",
       "4                         26                 3   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  وكان الرئيس الاوكراني المؤقت الكسندر تورتشينوف...   \n",
       "1  بحلول عام 2050 ستحتاج مصر الي 21 مليار متر مكع...   \n",
       "2  وذكرت وكاله الانباء المحليه جي ان اس ان جماعه ...   \n",
       "3  ووقع اختياره علي واد عمقه 800 متر محاط بثماني ...   \n",
       "4  مسلح حوثي اب وقال المصدر ان المسلحين الحوثيين ...   \n",
       "\n",
       "                                        Stemmed_Text  \\\n",
       "0  وكان رئس وكر ؤقت كسندر تورتشينوف امر سحب قوت ا...   \n",
       "1  حلل عام 2050 حاج مصر الي 21 لير متر كعب حصت حل...   \n",
       "2  ذكر وكل باء حله جي ان اس ان جمع جيش حمد تشدد ا...   \n",
       "3  وقع خير علي واد عمق 800 متر حاط بثم قمم حده تش...   \n",
       "4  سلح حوث اب وقل صدر ان سلح حوث هجم شطء حرك همي ...   \n",
       "\n",
       "                                     Lemmatized_Text  \n",
       "0  كان رئيس الاوكراني المؤقت الكسندر تورتشينوف مر...  \n",
       "1  حلول عام 2050 احتاج مصر ال 21 مليار متر مكعب ح...  \n",
       "2  ذكر كال الانباء المحليه جي ان اس ان جماع جيش م...  \n",
       "3  وقع اختيار علي وادي عمق 800 متر محاط بثماني قم...  \n",
       "4  مسلح حوثي اب قال مصدر ان مسلح الحوثيين هاجم نش...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = pd.read_csv('../preprocessed_data/train_inputs.csv')\n",
    "train_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_Text</th>\n",
       "      <th>Punctuation_Counts_before</th>\n",
       "      <th>Diacritic_Counts</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بدأت القوات الأوكرانيه الانسحاب من شبه جزيره ا...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>بدأت القوات الأوكرانيه الانسحاب من شبه جزيره ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>هل سيتم تغيير العباره الشهيره للمؤرخ اليوناني...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>هل سيتم تغيير العباره الشهيره للمؤرخ اليوناني...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قالت الشرطه في القطاع الهندي من إقليم كشمير إن...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>قالت الشرطه في القطاع الهندي من إقليم كشمير إن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>في عام 816  تجول راهب يدعي كوكاي  في المنحدرات...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>في عام 816  تجول راهب يدعي كوكاي  في المنحدرات...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>أكد مصدر في  الحراك التهامي  لأبناء محافظه الح...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>أكد مصدر في  الحراك التهامي  لأبناء محافظه الح...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_Text  \\\n",
       "0  بدأت القوات الأوكرانيه الانسحاب من شبه جزيره ا...   \n",
       "1   هل سيتم تغيير العباره الشهيره للمؤرخ اليوناني...   \n",
       "2  قالت الشرطه في القطاع الهندي من إقليم كشمير إن...   \n",
       "3  في عام 816  تجول راهب يدعي كوكاي  في المنحدرات...   \n",
       "4  أكد مصدر في  الحراك التهامي  لأبناء محافظه الح...   \n",
       "\n",
       "   Punctuation_Counts_before  Diacritic_Counts  \\\n",
       "0                          3                 0   \n",
       "1                          8                 0   \n",
       "2                          3                 0   \n",
       "3                          9                 0   \n",
       "4                          3                 0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  بدأت القوات الأوكرانيه الانسحاب من شبه جزيره ا...  \n",
       "1   هل سيتم تغيير العباره الشهيره للمؤرخ اليوناني...  \n",
       "2  قالت الشرطه في القطاع الهندي من إقليم كشمير إن...  \n",
       "3  في عام 816  تجول راهب يدعي كوكاي  في المنحدرات...  \n",
       "4  أكد مصدر في  الحراك التهامي  لأبناء محافظه الح...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('../preprocessed_data/train_labels.csv')\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>وكان الرئيس الاوكراني المؤقت الكسندر تورتشينوف...</td>\n",
       "      <td>بدأت القوات الأوكرانيه الانسحاب من شبه جزيره ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بحلول عام 2050 ستحتاج مصر الي 21 مليار متر مكع...</td>\n",
       "      <td>هل سيتم تغيير العباره الشهيره للمؤرخ اليوناني...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وذكرت وكاله الانباء المحليه جي ان اس ان جماعه ...</td>\n",
       "      <td>قالت الشرطه في القطاع الهندي من إقليم كشمير إن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ووقع اختياره علي واد عمقه 800 متر محاط بثماني ...</td>\n",
       "      <td>في عام 816  تجول راهب يدعي كوكاي  في المنحدرات...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مسلح حوثي اب وقال المصدر ان المسلحين الحوثيين ...</td>\n",
       "      <td>أكد مصدر في  الحراك التهامي  لأبناء محافظه الح...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  وكان الرئيس الاوكراني المؤقت الكسندر تورتشينوف...   \n",
       "1  بحلول عام 2050 ستحتاج مصر الي 21 مليار متر مكع...   \n",
       "2  وذكرت وكاله الانباء المحليه جي ان اس ان جماعه ...   \n",
       "3  ووقع اختياره علي واد عمقه 800 متر محاط بثماني ...   \n",
       "4  مسلح حوثي اب وقال المصدر ان المسلحين الحوثيين ...   \n",
       "\n",
       "                                             summary  \n",
       "0  بدأت القوات الأوكرانيه الانسحاب من شبه جزيره ا...  \n",
       "1   هل سيتم تغيير العباره الشهيره للمؤرخ اليوناني...  \n",
       "2  قالت الشرطه في القطاع الهندي من إقليم كشمير إن...  \n",
       "3  في عام 816  تجول راهب يدعي كوكاي  في المنحدرات...  \n",
       "4  أكد مصدر في  الحراك التهامي  لأبناء محافظه الح...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = train_inputs.copy().rename(columns={'cleaned_text': 'text'})\n",
    "df_y = train_labels.copy().rename(columns={'cleaned_text': 'summary'})\n",
    "df = pd.concat([df_x['text'], df_y['summary']], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "model = 'moussaKam/AraBART'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "# Tokenizes the input dataframe to match the used AraBART model\n",
    "# Returns a dictionary {input_ids, attention_mask, summary}\n",
    "def tokenize(df):\n",
    "    model_input = [row for row in df['text']]\n",
    "    model_input = tokenizer(model_input, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(df['summary'], max_length=max_target_length, truncation=True)\n",
    "    \n",
    "    model_input['labels'] = labels['input_ids']\n",
    "    return model_input\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different lengths??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3546: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = train_dataset.map(tokenize, batched=True)\n",
    "\n",
    "#tokenized_data = tokenize(train_dataset)tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/ahmed/.cache/huggingface/hub/models--moussaKam--AraBART/snapshots/cb67d617b84f52755c0cbf34684a41fe0f01cdb1/config.json\n",
      "Model config MBartConfig {\n",
      "  \"_name_or_path\": \"moussaKam/AraBART\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"MBartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"BarthezTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/ahmed/.cache/huggingface/hub/models--moussaKam--AraBART/snapshots/cb67d617b84f52755c0cbf34684a41fe0f01cdb1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MBartForConditionalGeneration.\n",
      "\n",
      "All the weights of MBartForConditionalGeneration were initialized from the model checkpoint at moussaKam/AraBART.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "pre_trained_model = AutoModelForSeq2SeqLM.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "model_name = 'AraBART'\n",
    "arguments = Seq2SeqTrainingArguments(\n",
    "    model_name,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14070 [12:40<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    pre_trained_model,\n",
    "    arguments,\n",
    "    train_dataset=tokenized_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 37519\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 14070\n",
      "  Number of trainable parameters = 139221504\n",
      "  0%|          | 29/14070 [19:45<123:25:29, 31.65s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=trainer.predict(tokenized_data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_str=tokenizer.batch_decode(outputs.predictions, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from rouge) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrouge\u001b[39;00m \u001b[39mimport\u001b[39;00m Rouge\n\u001b[0;32m----> 3\u001b[0m scores \u001b[39m=\u001b[39m Rouge()\u001b[39m.\u001b[39mget_scores(model, tokenized_data[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "score = Rouge().get_scores(out_str, tokenized_data['summary'])\n",
    "\n",
    "for i in range(0, 3):\n",
    "    print(\"rouge-1 :\" , score[i]['rouge-1']['f']*100)\n",
    "    print(\"rouge-2 :\" , score[i]['rouge-2']['f']*100)\n",
    "    print(\"rouge-l :\" , score[i]['rouge-l']['f']*100)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
